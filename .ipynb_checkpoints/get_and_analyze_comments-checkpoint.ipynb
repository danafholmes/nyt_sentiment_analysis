{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e844230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2da1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "import re\n",
    "from segtok.segmenter import split_single\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c79a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['NYT_SECRET']\n",
    "comments_endpoint = \"https://api.nytimes.com/svc/community/v3/user-content/url.json\"\n",
    "\n",
    "comments_api_args = {\n",
    "    \"offset\": 0,\n",
    "    \"url\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a37d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to do API stuff\n",
    "\n",
    "def call_nyt_api(endpoint, api_key, api_args):\n",
    "    \"\"\"A (theoretically...) reusable function to call any NYT api endpoint.\n",
    "    api_args is a dict of parameters that are appended to the API request string\n",
    "    returns a json object\"\"\"\n",
    "    args = []\n",
    "    for arg in api_args.items():\n",
    "        full_arg = \"&{key}={value}\".format(key=arg[0],value=arg[1])\n",
    "        args.append(full_arg)\n",
    "    arg_string = ''.join(args)\n",
    "    request_string = (\"{endpoint}?api-key={api_key}{arg_string}\".format(endpoint=endpoint, api_key=api_key, arg_string=arg_string))\n",
    "    api_obj = requests.get(request_string)\n",
    "    print(f\"HTTP Response: {api_obj.status_code}\")\n",
    "    return api_obj.json()\n",
    "\n",
    "\n",
    "def get_comment_page(offset, url):\n",
    "    \"\"\"get a single page of comments. returns a JSON object\"\"\"\n",
    "    endpoint = comments_endpoint\n",
    "    return call_nyt_api(endpoint, api_key, {\"offset\": offset, \"url\": url})\n",
    "\n",
    "def get_all_comments(url):\n",
    "    \"\"\"iterate through all pages of comments. returns a JSONL string object\"\"\"\n",
    "    comments = []\n",
    "    page0 = get_comment_page(0,url)\n",
    "#     total_comments = page0[\"results\"][\"totalParentCommentsFound\"]\n",
    "# Just get 100 comments to test faster:\n",
    "    total_comments = 100\n",
    "    print(f\"Fetched Page 0. {total_comments} total comments found. Fetching {math.ceil(total_comments/25)} pages\")\n",
    "    for comment in page0[\"results\"][\"comments\"]:\n",
    "        comments.append({\"comment_id\": comment[\"commentID\"],\"comment\":comment[\"commentBody\"]})\n",
    "    offset = 25\n",
    "    #free tier api limit - sleep at least 6 seconds to avoid getting rate-limited\n",
    "    time.sleep(7)\n",
    "    while offset < total_comments:\n",
    "        page = get_comment_page(offset,url)\n",
    "        for comment in page[\"results\"][\"comments\"]:\n",
    "            comments.append({\"comment_id\": comment[\"commentID\"],\"comment\":comment[\"commentBody\"]})\n",
    "        print(f\"Fetched Page {offset/25}. {total_comments - offset} comments left to fetch.\")\n",
    "        offset += 25\n",
    "        #free tier api limit - sleep at least 6 seconds to avoid getting rate-limited\n",
    "        time.sleep(7)\n",
    "    comments_with_url = []\n",
    "    for comment in comments:\n",
    "        comments_with_url.append(json.dumps({\"article_url\": url, \"comment_id\": comment[\"comment_id\"], \"comment\": comment[\"comment\"]}))\n",
    "    comments_jsonl = '\\n'.join(comments_with_url)\n",
    "    return comments_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ebd0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \n",
    "    I stole this from stack overflow because it's fun :D \n",
    "    \n",
    "    https://stackoverflow.com/questions/3173320/text-progress-bar-in-terminal-with-block-characters\n",
    "    \n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent if int(float(percent)) < 100 else 100}% {suffix}', end = printEnd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e071a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to do sentiment analysis stuff\n",
    "\n",
    "def clean(raw):\n",
    "    \"\"\" Remove hyperlinks and markup \"\"\"\n",
    "    result = re.sub(\"<[a][^>]*>(.+?)</[a]>\", 'Link.', raw)\n",
    "    result = re.sub('&gt;', \"\", result)\n",
    "    result = re.sub('&#x27;', \"'\", result)\n",
    "    result = re.sub('&quot;', '\"', result)\n",
    "    result = re.sub('&#x2F;', ' ', result)\n",
    "    result = re.sub('<p>', ' ', result)\n",
    "    result = re.sub('</i>', '', result)\n",
    "    result = re.sub('&#62;', '', result)\n",
    "    result = re.sub('<i>', ' ', result)\n",
    "    result = re.sub(\"\\n\", '', result)\n",
    "    return result\n",
    "\n",
    "def make_sentences(text):\n",
    "    \"\"\" Break apart text into a list of sentences \"\"\"\n",
    "    sentences = [sent for sent in split_single(text)]\n",
    "    return sentences\n",
    "\n",
    "def predict(sentence):\n",
    "    \"\"\" Predict the sentiment of a sentence \"\"\"\n",
    "    if sentence == \"\":\n",
    "        return {'flair':0,'textblob':0}\n",
    "    text = Sentence(sentence)\n",
    "    # stacked_embeddings.embed(text)\n",
    "    classifier.predict(text)\n",
    "    value = text.labels[0].to_dict()['value']\n",
    "    #print(text.to_dict())\n",
    "    if value == 'POSITIVE':\n",
    "        flair_result = text.to_dict()['labels'][0]['confidence']\n",
    "    else:\n",
    "        flair_result = -(text.to_dict()['labels'][0]['confidence'])\n",
    "    if sentence == \"\":\n",
    "        textblob_result = 0\n",
    "    blob = TextBlob(sentence)\n",
    "    textblob_result = blob.sentiment.polarity\n",
    "    textblob_subjectivity = blob.sentiment.subjectivity\n",
    "    return {'flair':round(flair_result, 3), 'textblob':round(textblob_result,3), 'subjectivity':round(textblob_subjectivity,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01da8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Article URL: https://www.nytimes.com/2022/04/18/opinion/elizabeth-warren-democrats-biden-midterms.html\n"
     ]
    }
   ],
   "source": [
    "# gets the URL we want to analyze comments on\n",
    "\n",
    "url = input('Input Article URL: ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a373d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Response: 200\n",
      "Fetched Page 0. 100 total comments found. Fetching 4 pages\n",
      "HTTP Response: 200\n",
      "Fetched Page 1.0. 75 comments left to fetch.\n",
      "HTTP Response: 200\n",
      "Fetched Page 2.0. 50 comments left to fetch.\n",
      "HTTP Response: 200\n",
      "Fetched Page 3.0. 25 comments left to fetch.\n"
     ]
    }
   ],
   "source": [
    "# fetch all comments. this is a JSONL string, with the assumption that at some point I might want to put this in bigquery and do the sentiment analysis on vertexAI\n",
    "\n",
    "all_comments = get_all_comments(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9bafe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 17:04:52,481 loading file /Users/danaholmes/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier.load('en-sentiment')\n",
    "\n",
    "sentence_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f521da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reticulating Splines: |██████████████████████████████████████████████████| 100% Completee\r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "l = len(all_comments.splitlines())\n",
    "\n",
    "printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "for i, comment in enumerate(all_comments.splitlines(), start=1):\n",
    "    p = json.loads(comment)\n",
    "    # print(p[\"comment\"])\n",
    "    p_blob = p[\"comment\"]\n",
    "    sentences = make_sentences(clean(p_blob))\n",
    "    printProgressBar(i + 1, l, prefix = 'Reticulating Splines:', suffix = 'Complete', length = 50)\n",
    "    for sentence in sentences:\n",
    "        #print({'commentID': p[\"comment_id\"],'sentence':sentence, 'score':predict(sentence)})\n",
    "        prediction = predict(sentence)\n",
    "        sentence_scores.append({'commentID': p[\"comment_id\"],'sentence':sentence, 'flair_score':prediction['flair'], 'text_blob_score':prediction['textblob'], 'subjectivity':prediction['subjectivity']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a86e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "# print(sentence_scores[0])\n",
    "for sentence in sentence_scores:\n",
    "#     #print({\"comment_id\": sentence[\"commentID\"], \"sentence\": sentence[\"sentence\"], \"score\": sentence[\"score\"]})\n",
    "    df = df.append({\"comment_id\": sentence[\"commentID\"], \"sentence\": sentence[\"sentence\"], \"flair_score\": sentence[\"flair_score\"], \"textblob_score\": sentence[\"text_blob_score\"], \"subjectivity\": sentence[\"subjectivity\"]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aef3d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#df.loc[df['subjectivity'] > .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3337df44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Comments: 59\n",
      "Average Comment Scores:\n",
      "  Flair: -0.4401506658595642\n",
      "  TextBlob: 0.020380831315577073\n"
     ]
    }
   ],
   "source": [
    "#loc method to filter to only comments with subjectivity >.5\n",
    "average_by_comment = df.loc[df['subjectivity'] > .5].groupby(['comment_id'], as_index = False).mean()\n",
    "\n",
    "\n",
    "average_comment_score_flair = average_by_comment[\"flair_score\"].mean(axis = 'index')\n",
    "average_comment_score_textblob = average_by_comment[\"textblob_score\"].mean(axis = 'index')\n",
    "count_comments = average_by_comment[\"comment_id\"].count()\n",
    "# deviation = average_by_comment[\"score\"].std()\n",
    "\n",
    "print(f\"Total Comments: {count_comments}\")\n",
    "print(\"Average Comment Scores:\")\n",
    "print(f\"  Flair: {average_comment_score_flair}\")\n",
    "print(f\"  TextBlob: {average_comment_score_textblob}\")\n",
    "# print(f\"Standard Deviation: {deviation}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
